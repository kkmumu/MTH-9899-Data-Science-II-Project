{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.inspection import permutation_importance\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    # intraday return features\n",
    "    temp = df[df['Time']=='10:00:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id') - df[df['Time']=='17:30:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '10/17res'\n",
    "    features = temp.reset_index()\n",
    "\n",
    "    temp = df[df['Time']=='10:00:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id') - df[df['Time']=='17:30:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '10/17raw'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='16:00:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id') - df[df['Time']=='17:30:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '16/17res'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='16:00:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id') - df[df['Time']=='17:30:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '16/17raw'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    # 17:30 ma raw return features\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=1).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma1raw'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=3).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma3raw'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=5).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma5raw'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='RawNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=20).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma20raw'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    features['17ma1-3raw'] = features['17ma1raw'] - features['17ma3raw']\n",
    "    features['17ma1-5raw'] = features['17ma1raw'] - features['17ma5raw']\n",
    "    features['17ma1-20raw'] = features['17ma1raw'] - features['17ma20raw']\n",
    "\n",
    "    # 17:30 ma residual return features\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=1).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma1res'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=3).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma3res'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=5).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma5res'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='ResidualNoWinsorCumReturn winsorized',index='Date',columns='Id').rolling(window=20).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '17ma20res'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    features['17ma1-3res'] = features['17ma1res'] - features['17ma3res']\n",
    "    features['17ma1-5res'] = features['17ma1res'] - features['17ma5res']\n",
    "    features['17ma1-20res'] = features['17ma1res'] - features['17ma20res']\n",
    "\n",
    "    # market value\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='CleanMid winsorized',index='Date',columns='Id') * df[df['Time']=='17:30:00.000'].pivot_table(values='SharesOutstanding winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'market_value'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    # intraday volume features\n",
    "    temp = df[df['Time']=='10:00:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id') / df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '10/17vol'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = (df[df['Time']=='16:00:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id') - df[df['Time']=='10:00:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id')) / df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = '16/17vol'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    # turnover ma\n",
    "    temp = (df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id') / df[df['Time']=='17:30:00.000'].pivot_table(values='SharesOutstanding winsorized',index='Date',columns='Id')).rolling(window=1).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'turnover_ma1'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = (df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id') / df[df['Time']=='17:30:00.000'].pivot_table(values='SharesOutstanding winsorized',index='Date',columns='Id')).rolling(window=3).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'turnover_ma3'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = (df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id') / df[df['Time']=='17:30:00.000'].pivot_table(values='SharesOutstanding winsorized',index='Date',columns='Id')).rolling(window=5).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'turnover_ma5'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = (df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id') / df[df['Time']=='17:30:00.000'].pivot_table(values='SharesOutstanding winsorized',index='Date',columns='Id')).rolling(window=20).mean()\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'turnover_ma20'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    # original features \n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='estVol winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'estVol'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='CleanMid winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'cleanMid17'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='16:00:00.000'].pivot_table(values='CleanMid winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'cleanMid16'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='10:00:00.000'].pivot_table(values='CleanMid winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'cleanMid10'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    temp = df[df['Time']=='17:30:00.000'].pivot_table(values='CumVolume winsorized',index='Date',columns='Id')\n",
    "    temp = temp.unstack()\n",
    "    temp.name = 'vol17'\n",
    "    temp = temp.reset_index()\n",
    "    features = features.merge(temp,on=['Id','Date'])\n",
    "\n",
    "    # Normalization\n",
    "    #features.iloc[:,2:] = (features.iloc[:,2:] - features.iloc[:,2:].mean())/features.iloc[:,2:].std()\n",
    "\n",
    "    # Merging with target\n",
    "    target = df[df[\"Time\"] == \"17:30:00.000\"][['Date','Id','ResidualNoWinsorCumReturn winsorized']].copy()\n",
    "    merged = features.merge(target ,on =['Date','Id']).drop_duplicates()\n",
    "    merged = merged.sort_values(['Id','Date'],ascending = [True, True])\n",
    "    merged[\"y\"] = merged.groupby(['Id'])[\"ResidualNoWinsorCumReturn winsorized\"].shift(-1)\n",
    "    merged = merged.dropna(how = 'any')\n",
    "    merged = merged.sort_values('Date',ascending=True)\n",
    "    merged_with_dates = merged\n",
    "    merged_with_dates.to_csv(\"merged_with_dates.csv\")\n",
    "    merged = merged.drop([\"Id\", \"Date\",\"ResidualNoWinsorCumReturn winsorized\"], axis = 1)\n",
    "    merged.to_csv('beforeTrainning.csv')\n",
    "    return merged, merged_with_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10/17res</th>\n",
       "      <th>10/17raw</th>\n",
       "      <th>16/17res</th>\n",
       "      <th>16/17raw</th>\n",
       "      <th>17ma1raw</th>\n",
       "      <th>17ma3raw</th>\n",
       "      <th>17ma5raw</th>\n",
       "      <th>17ma20raw</th>\n",
       "      <th>17ma1-3raw</th>\n",
       "      <th>17ma1-5raw</th>\n",
       "      <th>...</th>\n",
       "      <th>turnover_ma1</th>\n",
       "      <th>turnover_ma3</th>\n",
       "      <th>turnover_ma5</th>\n",
       "      <th>turnover_ma20</th>\n",
       "      <th>estVol</th>\n",
       "      <th>cleanMid17</th>\n",
       "      <th>cleanMid16</th>\n",
       "      <th>cleanMid10</th>\n",
       "      <th>vol17</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.014479</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.002551</td>\n",
       "      <td>-4.328447e-03</td>\n",
       "      <td>0.012672</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>-0.015223</td>\n",
       "      <td>...</td>\n",
       "      <td>5127.454439</td>\n",
       "      <td>6982.580835</td>\n",
       "      <td>11541.301587</td>\n",
       "      <td>10753.510582</td>\n",
       "      <td>0.296036</td>\n",
       "      <td>33.452305</td>\n",
       "      <td>33.503600</td>\n",
       "      <td>33.599230</td>\n",
       "      <td>872180.0</td>\n",
       "      <td>-0.017619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521779</th>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-0.013599</td>\n",
       "      <td>-4.222190e-03</td>\n",
       "      <td>-0.015091</td>\n",
       "      <td>-0.002486</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>...</td>\n",
       "      <td>4172.375545</td>\n",
       "      <td>3466.191410</td>\n",
       "      <td>3757.401356</td>\n",
       "      <td>2936.059761</td>\n",
       "      <td>0.178838</td>\n",
       "      <td>17.535980</td>\n",
       "      <td>17.494583</td>\n",
       "      <td>17.875440</td>\n",
       "      <td>4175388.0</td>\n",
       "      <td>-0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523534</th>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-6.530792e-04</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.004395</td>\n",
       "      <td>-0.017631</td>\n",
       "      <td>-0.018442</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.178894</td>\n",
       "      <td>1576.224406</td>\n",
       "      <td>1625.117301</td>\n",
       "      <td>1100.684447</td>\n",
       "      <td>0.197799</td>\n",
       "      <td>10.543943</td>\n",
       "      <td>10.556362</td>\n",
       "      <td>10.771629</td>\n",
       "      <td>484379.0</td>\n",
       "      <td>0.005427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524559</th>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.008458</td>\n",
       "      <td>-5.796803e-03</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>-0.003891</td>\n",
       "      <td>...</td>\n",
       "      <td>1991.979684</td>\n",
       "      <td>1418.626035</td>\n",
       "      <td>1253.361174</td>\n",
       "      <td>1726.009481</td>\n",
       "      <td>0.255014</td>\n",
       "      <td>8.605063</td>\n",
       "      <td>8.594749</td>\n",
       "      <td>8.726646</td>\n",
       "      <td>882447.0</td>\n",
       "      <td>0.022712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525278</th>\n",
       "      <td>-0.009049</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>-0.003221</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>-1.123333e-08</td>\n",
       "      <td>-0.007774</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>...</td>\n",
       "      <td>1544.120471</td>\n",
       "      <td>1322.711271</td>\n",
       "      <td>1227.455657</td>\n",
       "      <td>1456.009146</td>\n",
       "      <td>0.198565</td>\n",
       "      <td>20.052948</td>\n",
       "      <td>19.937037</td>\n",
       "      <td>20.193700</td>\n",
       "      <td>305566.0</td>\n",
       "      <td>-0.001233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474687</th>\n",
       "      <td>-0.003156</td>\n",
       "      <td>-0.002843</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>1.659979e-03</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.001230</td>\n",
       "      <td>...</td>\n",
       "      <td>755.496437</td>\n",
       "      <td>859.870155</td>\n",
       "      <td>1097.978782</td>\n",
       "      <td>2185.348603</td>\n",
       "      <td>0.124384</td>\n",
       "      <td>109.489080</td>\n",
       "      <td>109.423294</td>\n",
       "      <td>109.178300</td>\n",
       "      <td>69860.0</td>\n",
       "      <td>0.005219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620200</th>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005335</td>\n",
       "      <td>-0.005509</td>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>2.318624e-03</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>...</td>\n",
       "      <td>1072.835540</td>\n",
       "      <td>1005.341016</td>\n",
       "      <td>1437.991572</td>\n",
       "      <td>2256.730451</td>\n",
       "      <td>0.097487</td>\n",
       "      <td>85.336110</td>\n",
       "      <td>85.126970</td>\n",
       "      <td>84.881970</td>\n",
       "      <td>139268.0</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11908</th>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>5.823757e-03</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>-0.003990</td>\n",
       "      <td>-0.002486</td>\n",
       "      <td>...</td>\n",
       "      <td>3146.915786</td>\n",
       "      <td>3221.191763</td>\n",
       "      <td>2999.656179</td>\n",
       "      <td>3712.759845</td>\n",
       "      <td>0.159906</td>\n",
       "      <td>47.260170</td>\n",
       "      <td>47.526077</td>\n",
       "      <td>47.469370</td>\n",
       "      <td>139122.0</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719403</th>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.011761</td>\n",
       "      <td>5.547418e-03</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.020993</td>\n",
       "      <td>...</td>\n",
       "      <td>882.373592</td>\n",
       "      <td>592.626950</td>\n",
       "      <td>938.420333</td>\n",
       "      <td>1328.093235</td>\n",
       "      <td>0.174713</td>\n",
       "      <td>12.221778</td>\n",
       "      <td>12.248676</td>\n",
       "      <td>12.295748</td>\n",
       "      <td>379523.0</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695443</th>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.008496</td>\n",
       "      <td>-4.872400e-04</td>\n",
       "      <td>-0.004770</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>-0.003726</td>\n",
       "      <td>...</td>\n",
       "      <td>1342.165462</td>\n",
       "      <td>1258.546204</td>\n",
       "      <td>1613.186252</td>\n",
       "      <td>3071.293714</td>\n",
       "      <td>0.217609</td>\n",
       "      <td>2.758390</td>\n",
       "      <td>2.756372</td>\n",
       "      <td>2.770494</td>\n",
       "      <td>2619707.0</td>\n",
       "      <td>-0.000680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769082 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10/17res  10/17raw  16/17res  16/17raw  17ma1raw      17ma3raw  \\\n",
       "19     -0.014479  0.004383  0.003725  0.001532 -0.002551 -4.328447e-03   \n",
       "521779  0.006544  0.019172  0.001098 -0.002364 -0.013599 -4.222190e-03   \n",
       "523534  0.007003  0.021363  0.002370  0.001177 -0.018284 -6.530792e-04   \n",
       "524559  0.000216  0.014031  0.003584 -0.001199 -0.008458 -5.796803e-03   \n",
       "525278 -0.009049  0.006995 -0.003221 -0.005797  0.006212 -1.123333e-08   \n",
       "...          ...       ...       ...       ...       ...           ...   \n",
       "474687 -0.003156 -0.002843 -0.002389 -0.000601  0.000601  1.659979e-03   \n",
       "620200 -0.005474 -0.005335 -0.005509 -0.002454  0.000700  2.318624e-03   \n",
       "11908   0.002591  0.004417  0.002889  0.005610  0.001834  5.823757e-03   \n",
       "719403  0.009592  0.006035  0.002739  0.002199 -0.011761  5.547418e-03   \n",
       "695443  0.000463  0.004378 -0.002990 -0.000732 -0.008496 -4.872400e-04   \n",
       "\n",
       "        17ma5raw  17ma20raw  17ma1-3raw  17ma1-5raw  ...  turnover_ma1  \\\n",
       "19      0.012672   0.001606    0.001777   -0.015223  ...   5127.454439   \n",
       "521779 -0.015091  -0.002486   -0.009377    0.001492  ...   4172.375545   \n",
       "523534  0.000158  -0.004395   -0.017631   -0.018442  ...   1364.178894   \n",
       "524559 -0.004567   0.005819   -0.002661   -0.003891  ...   1991.979684   \n",
       "525278 -0.007774  -0.000493    0.006212    0.013987  ...   1544.120471   \n",
       "...          ...        ...         ...         ...  ...           ...   \n",
       "474687  0.001832   0.004811   -0.001059   -0.001230  ...    755.496437   \n",
       "620200 -0.000727   0.000411   -0.001619    0.001427  ...   1072.835540   \n",
       "11908   0.004319   0.003771   -0.003990   -0.002486  ...   3146.915786   \n",
       "719403  0.009233  -0.000683   -0.017308   -0.020993  ...    882.373592   \n",
       "695443 -0.004770   0.003797   -0.008009   -0.003726  ...   1342.165462   \n",
       "\n",
       "        turnover_ma3  turnover_ma5  turnover_ma20    estVol  cleanMid17  \\\n",
       "19       6982.580835  11541.301587   10753.510582  0.296036   33.452305   \n",
       "521779   3466.191410   3757.401356    2936.059761  0.178838   17.535980   \n",
       "523534   1576.224406   1625.117301    1100.684447  0.197799   10.543943   \n",
       "524559   1418.626035   1253.361174    1726.009481  0.255014    8.605063   \n",
       "525278   1322.711271   1227.455657    1456.009146  0.198565   20.052948   \n",
       "...              ...           ...            ...       ...         ...   \n",
       "474687    859.870155   1097.978782    2185.348603  0.124384  109.489080   \n",
       "620200   1005.341016   1437.991572    2256.730451  0.097487   85.336110   \n",
       "11908    3221.191763   2999.656179    3712.759845  0.159906   47.260170   \n",
       "719403    592.626950    938.420333    1328.093235  0.174713   12.221778   \n",
       "695443   1258.546204   1613.186252    3071.293714  0.217609    2.758390   \n",
       "\n",
       "        cleanMid16  cleanMid10      vol17         y  \n",
       "19       33.503600   33.599230   872180.0 -0.017619  \n",
       "521779   17.494583   17.875440  4175388.0 -0.000857  \n",
       "523534   10.556362   10.771629   484379.0  0.005427  \n",
       "524559    8.594749    8.726646   882447.0  0.022712  \n",
       "525278   19.937037   20.193700   305566.0 -0.001233  \n",
       "...            ...         ...        ...       ...  \n",
       "474687  109.423294  109.178300    69860.0  0.005219  \n",
       "620200   85.126970   84.881970   139268.0  0.001534  \n",
       "11908    47.526077   47.469370   139122.0  0.001472  \n",
       "719403   12.248676   12.295748   379523.0  0.001981  \n",
       "695443    2.756372    2.770494  2619707.0 -0.000680  \n",
       "\n",
       "[769082 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Lenovo\\Python workshop\\project\\merged_data_fillna_timeid.csv\", sep = \",\")\n",
    "m, mwd = compute_features(df)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwd.to_csv(\"mvd.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = normalize(m)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = m.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature hotmap captures only the pairwise correlation between the features\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = m.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateVIF(X):\n",
    "    vif_data = pd.DataFrame({\n",
    "        \"Names\": X.columns,\n",
    "        \"VIF\": [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    })\n",
    "    return vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = calculateVIF(m)\n",
    "while(vif[\"VIF\"].max() >= 10):\n",
    "    drop_var = vif[vif.VIF == vif[\"VIF\"].max()][\"Names\"]\n",
    "    m = m.drop(drop_var, axis = 1)\n",
    "    vif = calculateVIF(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_var = ['10/17res', '10/17raw', '16/17res', '16/17raw', '17ma3raw', '17ma3res',\n",
    "       '17ma5res', 'market_value', '10/17vol', '16/17vol', 'turnover_ma1',\n",
    "       'turnover_ma20', 'estVol', 'cleanMid17', 'vol17', 'y']\n",
    "m = m.loc[:,keep_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['10/17res', '10/17raw', '16/17res', '16/17raw', '17ma3raw', '17ma3res',\n",
       "       '17ma5res', 'market_value', '10/17vol', '16/17vol', 'turnover_ma1',\n",
       "       'turnover_ma20', 'estVol', 'cleanMid17', 'vol17', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-valid-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test data split\n",
    "train_valid = m.loc[list(mwd[mwd[\"Date\"] < 20170101].index)] # 2014-2016\n",
    "test = m.loc[list(mwd[mwd[\"Date\"] >= 20170101].index)] # 2017\n",
    "\n",
    "X_train_valid, y_train_valid = train_valid.iloc[: , :-1], train_valid[\"y\"]\n",
    "X_test, y_test = test.iloc[: , :-1], test[\"y\"]\n",
    "\n",
    "# scale the features in train set\n",
    "sc = StandardScaler()\n",
    "X_train_valid_scaled = sc.fit_transform(X_train_valid)\n",
    "X_train_valid_scaled = pd.DataFrame(data = X_train_valid_scaled, columns = X_train_valid.columns, index = X_train_valid.index)\n",
    "\n",
    "# do the same scaling to test set\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(data = X_test_scaled, columns = X_test.columns)\n",
    "\n",
    "X_train = X_train_valid.loc[list(mwd[mwd[\"Date\"] < 20160101].index)] # 2014-2015\n",
    "X_valid = X_train_valid.loc[list(mwd[(mwd[\"Date\"] >= 20160101) & (mwd[\"Date\"] < 20170101)].index)] # 2016\n",
    "y_train = m.loc[list(mwd[mwd[\"Date\"] < 20160101].index)][\"y\"]\n",
    "y_valid = m.loc[list(mwd[(mwd[\"Date\"] >= 20160101) & (mwd[\"Date\"] < 20170101)].index)][\"y\"]\n",
    "\n",
    "\n",
    "# X_train_scaled = X_train_valid_scaled.loc[list(mwd[mwd[\"Date\"] < 20160101].index)] # 2014-2015\n",
    "# X_valid_scaled = X_train_valid_scaled.loc[list(mwd[(mwd[\"Date\"] >= 20160101) & (mwd[\"Date\"] < 20170101)].index)] # 2016\n",
    "# y_train = m.loc[list(mwd[mwd[\"Date\"] < 20160101].index)][\"y\"]\n",
    "# y_valid = m.loc[list(mwd[(mwd[\"Date\"] >= 20160101) & (mwd[\"Date\"] < 20170101)].index)][\"y\"]\n",
    "\n",
    "# X_train_valid_scaled = X_train_valid_scaled.reset_index(drop=True)\n",
    "# X_train_scaled = X_train_scaled.reset_index(drop=True)\n",
    "# X_valid_scaled = X_valid_scaled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((378660, 15),\n",
       " (378660,),\n",
       " (195707, 15),\n",
       " (195707,),\n",
       " (574367, 15),\n",
       " (574367,),\n",
       " (194715, 15),\n",
       " (194715,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_train_valid.shape, y_train_valid.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(model, y_true, X):\n",
    "    r2_weight = 1 / np.array(X['estVol'])\n",
    "    r2_weight = r2_weight / r2_weight.sum()\n",
    "    y_pred = model.predict(X)\n",
    "    return r2_score(y_true, y_pred, sample_weight = r2_weight)\n",
    "\n",
    "def cv_evaluate(model, X, y, how, cv_folds = 5):\n",
    "    # cross validation\n",
    "    cv_train_r2, cv_valid_r2 = [], []    \n",
    "    \n",
    "    if how == \"walk_forwarding\":\n",
    "        tscv = TimeSeriesSplit(n_splits = cv_folds)\n",
    "        splits = tscv.split(X)\n",
    "        for train_index, test_index in splits:\n",
    "            X_train_cv, X_valid_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train_cv, y_valid_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv)\n",
    "            cv_train_r2 += [weighted_mse(model, y_train_cv, X_train_cv)]\n",
    "            cv_valid_r2 += [weighted_mse(model, y_valid_cv, X_valid_cv)]\n",
    "    else:\n",
    "        n_samples = len(X)\n",
    "        folds = n_samples // cv_folds\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(cv_folds): \n",
    "            start = i * folds  \n",
    "            stop = start + folds  \n",
    "            temp = int(0.8 * (stop - start)) + start #If you want to change the data ratio of train/Validation, change the 0.8 part.\n",
    "        \n",
    "            X_train_cv, X_valid_cv = X.iloc[start: temp], X.iloc[temp + margin: stop]\n",
    "            y_train_cv, y_valid_cv = y.iloc[start: temp], y.iloc[temp + margin: stop]\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv)\n",
    "            cv_train_r2 += [weighted_mse(model, y_train_cv, X_train_cv)]\n",
    "            cv_valid_r2 += [weighted_mse(model, y_valid_cv, X_valid_cv)]\n",
    "    \n",
    "    print(\"Cross Validation Report\")\n",
    "    print(f\"cv train r2: {np.array(cv_train_r2).mean()*100}%, cv valid r2: {np.array(cv_valid_r2).mean()*100}%\")\n",
    "    \n",
    "    return np.mean(cv_valid_r2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning(my_model, X, y, X_valid, y_valid, X_train_valid, y_train_valid, X_test, y_test, para_test, cv_folds = 5, how = \"walk_forwarding\"):\n",
    "    \n",
    "    # cross validation to select best variables\n",
    "    keys, values = zip(*para_test.items())\n",
    "    permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    weighted_r2_max = -float(\"inf\")\n",
    "    for p in permutations_dicts:\n",
    "        print('\\n',p)\n",
    "        my_model.set_params(**p)\n",
    "        weighted_r2 = cv_evaluate(my_model, X_train_valid, y_train_valid, how, cv_folds)\n",
    "        if weighted_r2 > weighted_r2_max:\n",
    "            weighted_r2_max = weighted_r2\n",
    "            best_paras = p\n",
    "    my_model.set_params(**best_paras)  \n",
    "    print(f\"best_paras: {best_paras}\")\n",
    "    \n",
    "    return best_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extratree_fit(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Fit the algorithm on the data\n",
    "    model.fit(X_train, y_train)         \n",
    "\n",
    "    # calculate weighted r2\n",
    "    weight_r2_train = weighted_mse(model, y_train, X_train)\n",
    "    weight_r2_test = weighted_mse(model, y_test, X_test)\n",
    "\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(f\"train r2: {weight_r2_train*100}%, test r2: {weight_r2_test*100}%\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### walk_forwarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations_extra = {'n_estimators': [50, 100, 150],\n",
    "                      'min_samples_leaf': [3,5],\n",
    "                      'min_samples_split': [2,4],\n",
    "                      'criterion': ['mse'],\n",
    "                      'max_depth': [8,32]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutations_extra = {'n_estimators': [50],\n",
    "#         'min_samples_leaf': [30],\n",
    "#         'min_samples_split': [25]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 3, 'min_samples_split': 2, 'criterion': 'mse', 'max_depth': 8}\n",
      "Cross Validation Report\n",
      "cv train r2: 0.917625135897151%, cv valid r2: 0.11839424321462122%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 3, 'min_samples_split': 2, 'criterion': 'mse', 'max_depth': 32}\n",
      "Cross Validation Report\n",
      "cv train r2: 47.50863512220659%, cv valid r2: -0.7661144266863085%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 3, 'min_samples_split': 4, 'criterion': 'mse', 'max_depth': 8}\n",
      "Cross Validation Report\n",
      "cv train r2: 0.9339834643993328%, cv valid r2: 0.12889945387197788%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 3, 'min_samples_split': 4, 'criterion': 'mse', 'max_depth': 32}\n",
      "Cross Validation Report\n",
      "cv train r2: 47.23347201302241%, cv valid r2: -0.7559577089146297%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 5, 'min_samples_split': 2, 'criterion': 'mse', 'max_depth': 8}\n",
      "Cross Validation Report\n",
      "cv train r2: 0.8731231288146035%, cv valid r2: 0.14310841854051626%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 5, 'min_samples_split': 2, 'criterion': 'mse', 'max_depth': 32}\n",
      "Cross Validation Report\n",
      "cv train r2: 36.589363913944204%, cv valid r2: -0.5265732261931166%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 5, 'min_samples_split': 4, 'criterion': 'mse', 'max_depth': 8}\n",
      "Cross Validation Report\n",
      "cv train r2: 0.8644095932508455%, cv valid r2: 0.133814947336377%\n",
      "\n",
      " {'n_estimators': 50, 'min_samples_leaf': 5, 'min_samples_split': 4, 'criterion': 'mse', 'max_depth': 32}\n",
      "Cross Validation Report\n",
      "cv train r2: 36.748041592497856%, cv valid r2: -0.5547850829554868%\n",
      "\n",
      " {'n_estimators': 100, 'min_samples_leaf': 3, 'min_samples_split': 2, 'criterion': 'mse', 'max_depth': 8}\n",
      "Cross Validation Report\n",
      "cv train r2: 0.9312602324951458%, cv valid r2: 0.1370303899331593%\n",
      "\n",
      " {'n_estimators': 100, 'min_samples_leaf': 3, 'min_samples_split': 2, 'criterion': 'mse', 'max_depth': 32}\n"
     ]
    }
   ],
   "source": [
    "my_model = ExtraTreesRegressor()\n",
    "best_paras = parameter_tuning(my_model, X_train, y_train, \n",
    "                              X_valid, y_valid, X_train_valid, y_train_valid, \n",
    "                              X_test, y_test, permutations_extra, cv_folds = 5, how = \"walk_forwarding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.set_params(**best_paras)  \n",
    "my_model = extratree_fit(my_model, X_train_valid, y_train_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = ExtraTreesRegressor()\n",
    "best_paras = parameter_tuning(my_model, X_train, y_train, \n",
    "                              X_valid, y_valid, X_train_valid, y_train_valid, \n",
    "                              X_test, y_test, permutations_extra, cv_folds = 5, how = \"rolling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.set_params(**best_paras)  \n",
    "my_model = extratree_fit(my_model, X_train_valid, y_train_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(my_model)\n",
    "perm.fit(X_train_valid, y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eli5.show_weights(perm, feature_names = X_train_valid.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm.feature_importances_ attribute is now available, it can be used\n",
    "# for feature selection - let's e.g. select features which increase\n",
    "# accuracy by at least 0.05:\n",
    "#sel = SelectFromModel(perm, threshold=0.001, prefit=True)\n",
    "#X_train_valid_new = pd.DataFrame(sel.transform(X_train_valid))\n",
    "#X_train_valid_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_paras = { 'max_depth': 4,\n",
    "                    'min_child_weight':5,\n",
    "                    'n_estimators': 100,\n",
    "                    'gamma': 0,\n",
    "                    'learning_rate': 0.1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = ExtraTreesRegressor()\n",
    "my_model.set_params(**best_paras)  \n",
    "my_model = extratree_fit(my_model, X_train_valid, y_train_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    my_model, X_train_valid, y_train_valid)\n",
    "\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(\n",
    "    result.importances[sorted_idx].T, vert=False, labels=X_train_valid.columns[sorted_idx]\n",
    ")\n",
    "ax.set_title(\"Permutation Importances (training set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_important = my_model.get_booster().get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "data.nlargest(40, columns=\"score\").plot(kind='bar', title='Feature Importances', figsize = (15,10)) ## plot top 40 features\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  y vs y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(X_test)  \n",
    "ans = pd.DataFrame.from_dict({'y_pred': y_pred, 'y': y_test})\n",
    "ans.to_csv('predictions.csv',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_plot(df, x_label, y_label, n_bins, path, w_label=None, scale=1, ax=None, **plot_kwargs):\n",
    "        \n",
    "        '''\n",
    "        create a bin plot with your feature (x_label), binned into (num_bin) quantiles \n",
    "        (with equal count), on the X-axis, and the corresponding mean of the target\n",
    "        variable (y_label) along with one standard error around mean on the Y-axis. \n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        x_label: str\n",
    "            label of feature x\n",
    "            \n",
    "        y_label: str\n",
    "            label of target\n",
    "            \n",
    "        w_label: str\n",
    "            label of weight if provided\n",
    "            \n",
    "        scale: float, default=1\n",
    "            where to plot the point with the bin = mean(bin) * scale\n",
    "            \n",
    "        ax: axes\n",
    "            ax to plot on, if None, the function will create one\n",
    "            \n",
    "        n_bins: int\n",
    "            number of bins\n",
    "            \n",
    "        **plot_kwargs: dict\n",
    "            keyword and arguments of ax.plot(x, y)\n",
    "        '''\n",
    "        \n",
    "        key = df[x_label].values\n",
    "        value = df[y_label].values\n",
    "        if w_label is not None:\n",
    "            w = df[w_label].values\n",
    "        \n",
    "            \n",
    "        sorted_idx = np.argsort(key)\n",
    "        chunks = np.array_split(sorted_idx, n_bins)\n",
    "              \n",
    "        # x axis on the plot: bin mean\n",
    "        x = np.ones(n_bins)\n",
    "        # boundary of the bins\n",
    "        b = np.ones(n_bins)\n",
    "        # y axis on the plot: bin mean\n",
    "        y = np.ones(n_bins)\n",
    "        # confidence of y: bin std\n",
    "        c = np.ones(n_bins)\n",
    "        \n",
    "        for bin_idx, idx in enumerate(chunks):\n",
    "            \n",
    "            x[bin_idx] = np.mean(key[idx]) * scale\n",
    "            b[bin_idx] = np.max(key[idx])\n",
    "            if w_label is not None:\n",
    "                y[bin_idx] = np.average(value[idx], weights=w[idx])\n",
    "            else:\n",
    "                y[bin_idx] = np.mean(value[idx])\n",
    "            c[bin_idx] = np.std(value[idx]) / np.sqrt(len(value[idx]))\n",
    "        \n",
    "        if ax is None: \n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "        ymin = np.min(y-c) - 0.5 * abs(np.min(y-c))\n",
    "        ymax = np.max(y+c) + 0.5 * abs(np.max(y-c))\n",
    "            \n",
    "        ax.plot(x, y, 'o-', **plot_kwargs)\n",
    "        ax.fill_between(x, y-c, y+c, color='b', alpha=0.1)\n",
    "        ax.vlines(b[:-1], ymin=ymin, ymax=ymax, color='grey')\n",
    "        ax.set_xticks(b[:-1])\n",
    "        ax.set_ylim(bottom=ymin, top=ymax)\n",
    "        ax.set_xlabel('bin boundaries, based on quantiles of {:s}'.format(x_label))\n",
    "        ax.set_ylabel('within-bin means and 1 std error of {:s}'.format(y_label))\n",
    "        ax.set_title('{:d} binned plot of {:s} against {:s}'.format(n_bins, y_label, x_label))\n",
    "        plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right') \n",
    "        fig.savefig(path+'bin_plot_'+x_label.replace('/','_')+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\\\Users\\\\Lenovo\\\\Desktop\\\\2022Spring\\\\9899 Machine learning\\\\project\\\\latex\\\\'\n",
    "bin_plot(ans, 'y_pred', 'y', 10, path, w_label=None, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y vs feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in m.columns:\n",
    "    bin_plot(m, col, 'y', 10, path, w_label=None, scale=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
